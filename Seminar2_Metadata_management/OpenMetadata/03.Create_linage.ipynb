{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Optional, Dict\n",
    "import re\n",
    "import pandas as pd\n",
    "from metadata.generated.schema.api.data.createPipeline import CreatePipelineRequest\n",
    "from metadata.generated.schema.api.lineage.addLineage import AddLineageRequest\n",
    "from metadata.generated.schema.entity.data.pipeline import Pipeline\n",
    "from metadata.generated.schema.entity.data.table import Table\n",
    "from metadata.generated.schema.entity.services.pipelineService import PipelineService\n",
    "from metadata.generated.schema.type.entityLineage import ColumnLineage, EntitiesEdge, LineageDetails\n",
    "from metadata.generated.schema.type.entityReference import EntityReference\n",
    "from metadata.ingestion.ometa.ometa_api import OpenMetadata"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# config\n",
    "lineage_path = f\"{DS_ROOT_PATH}/lineage_test.csv\"\n",
    "schema_fqn = f\"{DB_SERVICE_NAME}.{DB_NAME}.{SCHEMA_NAME}\""
   ],
   "id": "7765cb45ce092219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "def get_pipeline_entity_by_fqn(om_conn: OpenMetadata, pipeline_fqn: str):\n",
    "    return om_conn.get_by_name(entity=Pipeline, fqn=pipeline_fqn)\n",
    "\n",
    "\n",
    "# get the schema fqn\n",
    "def get_df_pipeline_fqn(lineage_df):\n",
    "    \"\"\"\n",
    "    This function returns the code reference which transform the table\n",
    "    :param lineage_df:\n",
    "    :type lineage_df:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    return lineage_df[OM_PIPE_FQN_COL_NAME].unique().tolist()\n",
    "\n",
    "\n",
    "def get_query_summary(code_ref_file_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    This function takes the code ref(e.g. a file path, or an url), get the summary of the script which transforms the table\n",
    "    :param code_ref_file_path:\n",
    "    :type code_ref_file_path: str\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    # Regular expression to find variables like query1, query2, query3, etc.\n",
    "    query_pattern = re.compile(r'query\\d+\\s*=\\s*[\\'\"](.+?)[\\'\"]', re.DOTALL)\n",
    "    query_summary = \"\"\n",
    "    if code_ref_file_path:\n",
    "        with open(code_ref_file_path, \"r\") as file:\n",
    "            file_content = file.read()\n",
    "\n",
    "        queries = query_pattern.findall(file_content)\n",
    "        for query in queries:\n",
    "            query_summary = f\"{query_summary}; \\n {query}\"\n",
    "    return query_summary\n",
    "\n",
    "\n",
    "def get_pipeline_service_by_name(om_conn: OpenMetadata, pipeline_service_fqn: str) -> PipelineService:\n",
    "    \"\"\"\n",
    "    This function takes a pipeline service fqn, then returns a pipeline service entity\n",
    "    :param om_conn:\n",
    "    :type om_conn:\n",
    "    :param pipeline_service_fqn: pipeline fully qualified name\n",
    "    :type pipeline_service_fqn: str\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    return om_conn.get_by_name(entity=PipelineService, fqn=pipeline_service_fqn)\n",
    "\n",
    "\n",
    "def get_table_by_name(om_conn: OpenMetadata, table_fqn: str) -> Table:\n",
    "    \"\"\"\n",
    "    This function takes a table fqn, then returns a table entity\n",
    "    :param om_conn: openmetadata connection\n",
    "    :type om_conn: OpenMetadata\n",
    "    :param table_fqn: table fully qualified name\n",
    "    :type table_fqn: str\n",
    "    :return: \n",
    "    :rtype: \n",
    "    \"\"\"\n",
    "    return om_conn.get_by_name(entity=Table, fqn=table_fqn)\n",
    "\n",
    "\n",
    "def generate_pipeline_params(code_ref: str) -> Dict:\n",
    "    resu = None\n",
    "    if code_ref:\n",
    "        dag_id = \"snds-constance-transformation\"\n",
    "        dag_description = \"this pipeline transform the snds raw data into constance simplyfy table\"\n",
    "        resu = {\"name\": dag_id,\n",
    "                \"description\": dag_description,\n",
    "                \"air_url\": f\"https://meta-ingestion.casd.local/dags/{dag_id}/grid\",\n",
    "                \"pipeline_loc\": \"/opt/airflow/dags/airflow_metadata_extraction.py\"}\n",
    "    return resu\n",
    "\n",
    "\n",
    "def build_query_pipeline(om_conn: OpenMetadata, code_ref: str, pipeline_service_fqn: str) -> Pipeline:\n",
    "    \"\"\"\n",
    "    This function takes the code ref, build a pipeline with the content of the ref\n",
    "    :param om_conn: Open metadata server connexion\n",
    "    :type om_conn:\n",
    "    :param code_ref: A fqn of the code reference(e.g. file path, url)\n",
    "    :type code_ref: str\n",
    "    :param pipeline_service_fqn: The target pipeline service\n",
    "    :type pipeline_service_fqn: str\n",
    "    :return: the generated pipeline\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    pipeline_service = get_pipeline_service_by_name(om_conn, pipeline_service_fqn)\n",
    "    pipeline_params = generate_pipeline_params(code_ref)\n",
    "    create_pipeline = CreatePipelineRequest(\n",
    "        # pipeline name generated from the code reference\n",
    "        name=pipeline_params[\"name\"],\n",
    "        # pipeline description generated from the code reference\n",
    "        description=pipeline_params[\"description\"],\n",
    "        sourceUrl=pipeline_params[\"air_url\"],\n",
    "        concurrency=5,\n",
    "        pipelineLocation=pipeline_params[\"pipeline_loc\"],\n",
    "        service=pipeline_service.fullyQualifiedName, )\n",
    "    pipeline_entity = om_conn.create_or_update(data=create_pipeline)\n",
    "    return pipeline_entity\n",
    "\n",
    "\n",
    "def build_column_lineage(lineage_df: pd.DataFrame, source_tab_fqn: str, dest_tab_fqn: str) -> List[ColumnLineage]:\n",
    "    \"\"\"\n",
    "    This function takes a filtered lineage dataframe which only contains one pair of source and dest table, it builds\n",
    "    all corresponding column lineage of the given pair. If no column lineage provided, return an empty list\n",
    "    :param lineage_df: A filtered table/column lineage dataframe\n",
    "    :type lineage_df: pd.Dataframe\n",
    "    :param source_tab_fqn:\n",
    "    :type source_tab_fqn:\n",
    "    :param dest_tab_fqn:\n",
    "    :type dest_tab_fqn:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    col_lineage_list = []\n",
    "    # group by the dest col name, and collect all linked source col in a list\n",
    "    dest_source_map = lineage_df.groupby(DEST_COL_NAME)[SRC_COL_NAME].agg(lambda x: list(x.unique())).reset_index()\n",
    "    # convert the dataframe to a list of dict\n",
    "    dest_source_map_list = dest_source_map.to_dict(orient=\"records\")\n",
    "    if dest_source_map_list:\n",
    "        # loop the list, for each row build a column lineage\n",
    "        for row in dest_source_map_list:\n",
    "            # complete the column fqn with the table fqn\n",
    "            target_col = f\"{dest_tab_fqn}.{row[DEST_COL_NAME]}\"\n",
    "            source_cols = [f\"{source_tab_fqn}.{col_name}\" for col_name in row[SRC_COL_NAME]]\n",
    "            column_lineage = ColumnLineage(\n",
    "                fromColumns=source_cols,\n",
    "                toColumn=target_col)\n",
    "            col_lineage_list.append(column_lineage)\n",
    "    return col_lineage_list\n",
    "\n",
    "\n",
    "def find_pipeline_fqn_by_dag(dag_file: str, om_conn: OpenMetadata):\n",
    "    \"\"\"\n",
    "    This function read a dag file and extract the dag id, it checks if this dag\n",
    "    has a mapping pipeline entity inside OM server or not. If it exists, return\n",
    "    the corresponding pipeline entity fqn, if not raise value error\n",
    "    :param om_conn:\n",
    "    :type om_conn:\n",
    "    :param dag_file:\n",
    "    :type dag_file:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    if dag_file is None or dag_file == '':\n",
    "        return None\n",
    "    try:\n",
    "        dag_id = get_dag_info(dag_file)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f'DAG file {dag_file} not found')\n",
    "        raise\n",
    "    except ValueError:\n",
    "        logger.error(f'DAG file {dag_file} has invalid format')\n",
    "        raise\n",
    "    pipeline_fqn = f\"{PIPELINE_SERVICE_NAME}.{dag_id}\"\n",
    "    # the type(pipeline_entity.id) returns\n",
    "    # metadata.generated.schema.type.basic.Uuid.\n",
    "    # so we can't store it in a dataframe\n",
    "    pipeline_entity = get_pipeline_entity_by_fqn(om_conn, pipeline_fqn)\n",
    "    if pipeline_entity:\n",
    "        logger.info(f\"find the pipeline {pipeline_entity.id}\")\n",
    "        return pipeline_fqn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f'Can not find the pipeline {pipeline_fqn} in the OM server. Load the dag file to airflow first please')"
   ],
   "id": "2fa96daf94ef84a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7fc558560f96e504"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
