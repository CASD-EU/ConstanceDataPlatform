{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T15:38:10.141741Z",
     "start_time": "2024-12-17T15:38:07.094057Z"
    }
   },
   "source": [
    "from typing import List, Optional, Dict\n",
    "import re\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "from metadata.generated.schema.entity.services.connections.metadata.openMetadataConnection import (OpenMetadataConnection, AuthProvider)\n",
    "from metadata.generated.schema.security.client.openMetadataJWTClientConfig import OpenMetadataJWTClientConfig\n",
    "from metadata.generated.schema.api.data.createPipeline import CreatePipelineRequest\n",
    "from metadata.generated.schema.api.lineage.addLineage import AddLineageRequest\n",
    "from metadata.generated.schema.entity.data.pipeline import Pipeline\n",
    "from metadata.generated.schema.entity.data.table import Table\n",
    "from metadata.generated.schema.entity.services.pipelineService import PipelineService\n",
    "from metadata.generated.schema.type.entityLineage import ColumnLineage, EntitiesEdge, LineageDetails\n",
    "from metadata.generated.schema.type.entityReference import EntityReference\n",
    "from metadata.ingestion.ometa.ometa_api import OpenMetadata"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:38:10.198920Z",
     "start_time": "2024-12-17T15:38:10.156800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from conf.creds.creds import om_oidc_token\n",
    "server_config = OpenMetadataConnection(\n",
    "    hostPort=\"http://datacatalog.casd.local/api\",\n",
    "    authProvider=AuthProvider.openmetadata,\n",
    "    securityConfig=OpenMetadataJWTClientConfig(\n",
    "        jwtToken=om_oidc_token,\n",
    "    ),\n",
    ")\n",
    "metadata = OpenMetadata(server_config)"
   ],
   "id": "312d3163d5cf4ba5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:38:11.088351Z",
     "start_time": "2024-12-17T15:38:11.068362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if it returns true, it means the connection is success\n",
    "metadata.health_check()"
   ],
   "id": "200de299a8b95268",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:38:12.236434Z",
     "start_time": "2024-12-17T15:38:12.228443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# conf for the table entity\n",
    "DB_SERVICE_NAME = \"Constances-Geography\"\n",
    "DB_NAME = \"hospitals_in_france\"\n",
    "SCHEMA_NAME = \"Geography\"\n",
    "\n",
    "# conf for lineage file\n",
    "project_root = pathlib.Path.cwd().parent.parent\n",
    "metadata_path = project_root / \"data\" / \"om\""
   ],
   "id": "cc52316e85b2c511",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:39:06.828055Z",
     "start_time": "2024-12-17T15:39:06.820560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# config\n",
    "lineage_path = f\"{metadata_path}/constances_hospital_lineage.csv\"\n",
    "schema_fqn = f\"{DB_SERVICE_NAME}.{DB_NAME}.{SCHEMA_NAME}\"\n",
    "\n",
    "# conf for pipeline service\n",
    "pipeline_service_name=\"test-service-pipeline\"\n",
    "pipe_fqn_col_name=\"pipeline_fqn\"\n",
    "\n",
    "code_ref_col_name=\"ref_code\""
   ],
   "id": "7765cb45ce092219",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:39:07.435243Z",
     "start_time": "2024-12-17T15:39:07.410442Z"
    }
   },
   "cell_type": "code",
   "source": "lineage_df = pd.read_csv(lineage_path)",
   "id": "dc2b824f374633ec",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:39:24.236466Z",
     "start_time": "2024-12-17T15:39:24.225972Z"
    }
   },
   "cell_type": "code",
   "source": "lineage_df.head()",
   "id": "4af2d1895c7f2569",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   origin_tab_name origin_col_name destinataire_tab_name  \\\n",
       "0  fr_communes_raw        geometry     fr_communes_clean   \n",
       "1  fr_communes_raw             nom     fr_communes_clean   \n",
       "2  fr_communes_raw           insee     fr_communes_clean   \n",
       "3   osm_france_raw              id   osm_hospitals_clean   \n",
       "4   osm_france_raw            tags   osm_hospitals_clean   \n",
       "\n",
       "  destinataire_col_name                                           ref_code  \n",
       "0              geometry  Seminar3_workflow_automation/airflow/dags/02.h...  \n",
       "1                  name  Seminar3_workflow_automation/airflow/dags/02.h...  \n",
       "2                 insee  Seminar3_workflow_automation/airflow/dags/02.h...  \n",
       "3                    id  Seminar3_workflow_automation/airflow/dags/02.h...  \n",
       "4                  tags  Seminar3_workflow_automation/airflow/dags/02.h...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_tab_name</th>\n",
       "      <th>origin_col_name</th>\n",
       "      <th>destinataire_tab_name</th>\n",
       "      <th>destinataire_col_name</th>\n",
       "      <th>ref_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr_communes_raw</td>\n",
       "      <td>geometry</td>\n",
       "      <td>fr_communes_clean</td>\n",
       "      <td>geometry</td>\n",
       "      <td>Seminar3_workflow_automation/airflow/dags/02.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr_communes_raw</td>\n",
       "      <td>nom</td>\n",
       "      <td>fr_communes_clean</td>\n",
       "      <td>name</td>\n",
       "      <td>Seminar3_workflow_automation/airflow/dags/02.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr_communes_raw</td>\n",
       "      <td>insee</td>\n",
       "      <td>fr_communes_clean</td>\n",
       "      <td>insee</td>\n",
       "      <td>Seminar3_workflow_automation/airflow/dags/02.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osm_france_raw</td>\n",
       "      <td>id</td>\n",
       "      <td>osm_hospitals_clean</td>\n",
       "      <td>id</td>\n",
       "      <td>Seminar3_workflow_automation/airflow/dags/02.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>osm_france_raw</td>\n",
       "      <td>tags</td>\n",
       "      <td>osm_hospitals_clean</td>\n",
       "      <td>tags</td>\n",
       "      <td>Seminar3_workflow_automation/airflow/dags/02.h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import ast\n",
    "\n",
    "def get_dag_info(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    This function read an airflow dag file, and return the dag id. If not valid, return None\n",
    "    :param file_path: the input dag file\n",
    "    :type file_path: str\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    # Initialize variables to store DAG ID\n",
    "    dag_id = None\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "        # Parse the file content into an AST\n",
    "        tree = ast.parse(file_content)\n",
    "        # Traverse the AST\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Call) and hasattr(node.func, 'id') and node.func.id == 'DAG':\n",
    "                for keyword in node.keywords:\n",
    "                    if keyword.arg == 'dag_id':\n",
    "                        dag_id = keyword.value.s\n",
    "    if dag_id is None:\n",
    "        raise ValueError('DAG id is not found')\n",
    "    return dag_id"
   ],
   "id": "79e6935f32b8b92b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def get_table_by_name(om_conn: OpenMetadata, table_fqn: str) -> Table:\n",
    "    \"\"\"\n",
    "    This function takes a table fqn, then returns a table entity\n",
    "    :param om_conn: openmetadata connection\n",
    "    :type om_conn: OpenMetadata\n",
    "    :param table_fqn: table fully qualified name\n",
    "    :type table_fqn: str\n",
    "    :return: \n",
    "    :rtype: \n",
    "    \"\"\"\n",
    "    return om_conn.get_by_name(entity=Table, fqn=table_fqn)\n",
    "\n",
    "\n",
    "def generate_pipeline_params(code_ref: str) -> Dict:\n",
    "    resu = None\n",
    "    if code_ref:\n",
    "        dag_id = \"constance-hospital-count\"\n",
    "        dag_description = \"this pipeline transform the snds raw data into constance simplyfy table\"\n",
    "        resu = {\"name\": dag_id,\n",
    "                \"description\": dag_description,\n",
    "                \"air_url\": f\"https://meta-ingestion.casd.local/dags/{dag_id}/grid\",\n",
    "                \"pipeline_loc\": \"/opt/airflow/dags/airflow_metadata_extraction.py\"}\n",
    "    return resu\n",
    "\n",
    "\n",
    "def build_query_pipeline(om_conn: OpenMetadata, code_ref: str, pipeline_service_fqn: str) -> Pipeline:\n",
    "    \"\"\"\n",
    "    This function takes the code ref, build a pipeline with the content of the ref\n",
    "    :param om_conn: Open metadata server connexion\n",
    "    :type om_conn:\n",
    "    :param code_ref: A fqn of the code reference(e.g. file path, url)\n",
    "    :type code_ref: str\n",
    "    :param pipeline_service_fqn: The target pipeline service\n",
    "    :type pipeline_service_fqn: str\n",
    "    :return: the generated pipeline\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    pipeline_service = get_pipeline_service_by_name(om_conn, pipeline_service_fqn)\n",
    "    pipeline_params = generate_pipeline_params(code_ref)\n",
    "    create_pipeline = CreatePipelineRequest(\n",
    "        # pipeline name generated from the code reference\n",
    "        name=pipeline_params[\"name\"],\n",
    "        # pipeline description generated from the code reference\n",
    "        description=pipeline_params[\"description\"],\n",
    "        sourceUrl=pipeline_params[\"air_url\"],\n",
    "        concurrency=5,\n",
    "        pipelineLocation=pipeline_params[\"pipeline_loc\"],\n",
    "        service=pipeline_service.fullyQualifiedName, )\n",
    "    pipeline_entity = om_conn.create_or_update(data=create_pipeline)\n",
    "    return pipeline_entity\n",
    "\n",
    "\n",
    "def build_column_lineage(lineage_df: pd.DataFrame, source_tab_fqn: str, dest_tab_fqn: str) -> List[ColumnLineage]:\n",
    "    \"\"\"\n",
    "    This function takes a filtered lineage dataframe which only contains one pair of source and dest table, it builds\n",
    "    all corresponding column lineage of the given pair. If no column lineage provided, return an empty list\n",
    "    :param lineage_df: A filtered table/column lineage dataframe\n",
    "    :type lineage_df: pd.Dataframe\n",
    "    :param source_tab_fqn:\n",
    "    :type source_tab_fqn:\n",
    "    :param dest_tab_fqn:\n",
    "    :type dest_tab_fqn:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    col_lineage_list = []\n",
    "    # group by the dest col name, and collect all linked source col in a list\n",
    "    dest_source_map = lineage_df.groupby(DEST_COL_NAME)[SRC_COL_NAME].agg(lambda x: list(x.unique())).reset_index()\n",
    "    # convert the dataframe to a list of dict\n",
    "    dest_source_map_list = dest_source_map.to_dict(orient=\"records\")\n",
    "    if dest_source_map_list:\n",
    "        # loop the list, for each row build a column lineage\n",
    "        for row in dest_source_map_list:\n",
    "            # complete the column fqn with the table fqn\n",
    "            target_col = f\"{dest_tab_fqn}.{row[DEST_COL_NAME]}\"\n",
    "            source_cols = [f\"{source_tab_fqn}.{col_name}\" for col_name in row[SRC_COL_NAME]]\n",
    "            column_lineage = ColumnLineage(\n",
    "                fromColumns=source_cols,\n",
    "                toColumn=target_col)\n",
    "            col_lineage_list.append(column_lineage)\n",
    "    return col_lineage_list\n",
    "\n",
    "\n",
    "def find_pipeline_fqn_by_dag(dag_file: str, om_conn: OpenMetadata):\n",
    "    \"\"\"\n",
    "    This function read a dag file and extract the dag id, it checks if this dag\n",
    "    has a mapping pipeline entity inside OM server or not. If it exists, return\n",
    "    the corresponding pipeline entity fqn, if not raise value error\n",
    "    :param om_conn:\n",
    "    :type om_conn:\n",
    "    :param dag_file:\n",
    "    :type dag_file:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    if dag_file is None or dag_file == '':\n",
    "        return None\n",
    "    try:\n",
    "        dag_id = get_dag_info(dag_file)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f'DAG file {dag_file} not found')\n",
    "        raise\n",
    "    except ValueError:\n",
    "        logger.error(f'DAG file {dag_file} has invalid format')\n",
    "        raise\n",
    "    pipeline_fqn = f\"{PIPELINE_SERVICE_NAME}.{dag_id}\"\n",
    "    # the type(pipeline_entity.id) returns\n",
    "    # metadata.generated.schema.type.basic.Uuid.\n",
    "    # so we can't store it in a dataframe\n",
    "    pipeline_entity = get_pipeline_entity_by_fqn(om_conn, pipeline_fqn)\n",
    "    if pipeline_entity:\n",
    "        logger.info(f\"find the pipeline {pipeline_entity.id}\")\n",
    "        return pipeline_fqn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f'Can not find the pipeline {pipeline_fqn} in the OM server. Load the dag file to airflow first please')"
   ],
   "id": "2fa96daf94ef84a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from metadata.generated.schema.type.entityLineage import ColumnLineage\n",
    "\n",
    "source_col_name=\"origin_col_name\"\n",
    "dest_col_name=\"destinataire_col_name\"\n",
    "\n",
    "def build_column_lineage(lineage_df,source_tab_fqn,dest_tab_fqn):\n",
    "    col_lineage_list=[]\n",
    "    # group by the dest col name, and collect all linked source col in a list\n",
    "    dest_source_map = lineage_df.groupby(dest_col_name)[source_col_name].agg(lambda x: list(x.unique())).reset_index()\n",
    "    # convert the dataframe to a list of dict\n",
    "    dest_source_map_list = dest_source_map.to_dict(orient=\"records\")\n",
    "    if dest_source_map_list:\n",
    "        # loop the list, for each row build a column lineage\n",
    "        for row in dest_source_map_list:\n",
    "            target_col=f\"{dest_tab_fqn}.{row[dest_col_name]}\"\n",
    "            # add\n",
    "            source_cols=[f\"{source_tab_fqn}.{col_name}\" for col_name in row[source_col_name]]\n",
    "            print(target_col)\n",
    "            print(source_cols)\n",
    "\n",
    "            column_lineage = ColumnLineage(\n",
    "            fromColumns=source_cols,\n",
    "            toColumn=target_col)\n",
    "            col_lineage_list.append(column_lineage)\n",
    "    return col_lineage_list"
   ],
   "id": "c22b058073b4377a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from metadata.generated.schema.entity.data.table import Table\n",
    "from metadata.generated.schema.api.lineage.addLineage import AddLineageRequest\n",
    "from metadata.generated.schema.type.entityLineage import EntitiesEdge, LineageDetails\n",
    "from metadata.generated.schema.type.entityReference import EntityReference\n",
    "\n",
    "\n",
    "\n",
    "def get_table_by_name(om_conn,table_fqn:str):\n",
    "    return om_conn.get_by_name(entity=Table, fqn=table_fqn)\n",
    "\n",
    "for row in source_dest_tabs:\n",
    "    source_tab_name=row[source_tab_col_name]\n",
    "    dest_tab_name=row[dest_tab_col_name]\n",
    "    source_tab_fqn=f\"{schema_fqn}.{source_tab_name}\"\n",
    "    dest_tab_fqn=f\"{schema_fqn}.{dest_tab_name}\"\n",
    "    source_tab_entity = get_table_by_name(metadata, source_tab_fqn)\n",
    "    dest_tab_entity = get_table_by_name(metadata, dest_tab_fqn)\n",
    "    # test if table exist or not\n",
    "    # if not exist, throw error\n",
    "    if source_tab_entity:\n",
    "        print(source_tab_entity.id)\n",
    "    else:\n",
    "        print(f\"can't find table {source_tab_name} in schema {schema_name}\")\n",
    "    if dest_tab_entity:\n",
    "        print(dest_tab_entity.id)\n",
    "    else:\n",
    "        print(f\"can't find table {dest_tab_name} in schema {schema_name}\")\n",
    "    # if exists, for each pair create a new add lineage request\n",
    "    # filter lineage df to keep only rows of the given source, dest tab pair\n",
    "    filtered_lineage_df=lineage_df[(lineage_df[source_tab_col_name]==source_tab_name) & (lineage_df[dest_tab_col_name]==dest_tab_name)]\n",
    "    # first create a lineage detail, it requires:\n",
    "    # - a query detail (string)\n",
    "    # - a column lineage list ([ColumnLineage]) optional\n",
    "    # - a pipeline (pipeline entity) optional\n",
    "    colum_lineage=build_column_lineage(filtered_lineage_df,source_tab_fqn,dest_tab_fqn)\n",
    "    pipeline_fqn = get_df_pipeline_fqn(filtered_lineage_df)\n",
    "\n",
    "    # if it has a code ref, parse the code ref to get the code detail\n",
    "    # then create a lineage detail entity\n",
    "    if pipeline_fqn:\n",
    "        # get pipeline entity\n",
    "        pipeline_entity = get_pipeline_by_fqn(pipeline_fqn[0])\n",
    "        query_detail=get_query_detail(pipeline_fqn[0])\n",
    "        lineage_details = LineageDetails(\n",
    "        sqlQuery=query_detail,\n",
    "        columnsLineage=colum_lineage,\n",
    "        pipeline=EntityReference(id=pipeline_entity.id, type=\"pipeline\"),)\n",
    "    else:\n",
    "        lineage_details=None\n",
    "    add_pipeline_lineage_request = AddLineageRequest(\n",
    "    edge=EntitiesEdge(\n",
    "        fromEntity=EntityReference(id=source_tab_entity.id, type=\"table\"),\n",
    "        toEntity=EntityReference(id=dest_tab_entity.id, type=\"table\"),\n",
    "        lineageDetails=lineage_details,\n",
    "    ),)\n",
    "\n",
    "    pipeline_lineage1 = metadata.add_lineage(data=add_pipeline_lineage_request)"
   ],
   "id": "7fc558560f96e504"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
